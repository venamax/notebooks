{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(http://thedataincubator.s3.amazonaws.com/coursedata/mldata/yelp_train_academic_dataset_review.json.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('yelp_train_academic_dataset_review.json').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "with gzip.open('../ml/yelp_train_academic_dataset_business.json.gz', 'rb') as f:\n",
    "    rest = f.readlines()\n",
    "\n",
    "    \n",
    "rest = map(lambda x: x.rstrip(), rest)\n",
    "\n",
    "import pandas as pd\n",
    "# each element of 'data' is an individual JSON object.\n",
    "# i want to convert it into an *array* of JSON objects\n",
    "# which, in and of itself, is one large JSON object\n",
    "# basically... add square brackets to the beginning\n",
    "# and end, and have all the individual business JSON objects\n",
    "# separated by a comma\n",
    "data_json_str = \"[\" + ','.join(rest) + \"]\"\n",
    "\n",
    "# now, load it into pandas\n",
    "df_rest = pd.read_json(data_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"votes\": {\"funny\": 0, \"useful\": 2, \"cool\": 1}, \"user_id\": \"Xqd0DzHaiyRqVH3WRG7hzg\", \"review_id\": \"15SdjuK7DmYqUAj6rjGowg\", \"stars\": 5, \"date\": \"2007-05-17\", \"text\": \"dr. goldberg offers everything i look for in a general practitioner.  he\\'s nice and easy to talk to without being patronizing; he\\'s always on time in seeing his patients; he\\'s affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i\\'m sitting here trying to think of any complaints i have about him, but i\\'m really drawing a blank.\", \"type\": \"review\", \"business_id\": \"vcNAWiLM4dR7D2nwwJ7nCA\"}\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = [json.loads(line)['text'] for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = [json.loads(line)['business_id'] for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stars = [json.loads(line)['stars'] for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012913, 1012913)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews), len(stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = [\n",
    "    {\"votes\": {\"funny\": 0, \"useful\": 0, \"cool\": 0}, \"user_id\": \"WsGQfLLy3YlP_S9jBE3j1w\", \"review_id\": \"kzFlI35hkmYA_vPSsMcNoQ\", \"stars\": 5, \"date\": \"2012-11-03\", \"text\": \"Love it!!!!! Love it!!!!!! love it!!!!!!!   Who doesn't love Culver's!\", \"type\": \"review\", \"business_id\": \"LRKJF43s9-3jG9Lgx4zODg\"},\n",
    "    {\"votes\": {\"funny\": 0, \"useful\": 0, \"cool\": 0}, \"user_id\": \"Veue6umxTpA3o1eEydowZg\", \"review_id\": \"Tfn4EfjyWInS-4ZtGAFNNw\", \"stars\": 3, \"date\": \"2013-12-30\", \"text\": \"Everything was great except for the burgers they are greasy and very charred compared to other stores.\", \"type\": \"review\", \"business_id\": \"LRKJF43s9-3jG9Lgx4zODg\"},\n",
    "    {\"votes\": {\"funny\": 0, \"useful\": 0, \"cool\": 0}, \"user_id\": \"u5xcw6LCnnMhddoxkRIgUA\", \"review_id\": \"ZYaS2P5EmK9DANxGTV48Tw\", \"stars\": 5, \"date\": \"2010-12-04\", \"text\": \"I really like both Chinese restaurants in town.  This one has outstanding crab rangoon.  Love the chicken with snow peas and mushrooms and General Tso Chicken.  Food is always ready in 10 minutes which is accurate.  Good place and they give you free pop.\", \"type\": \"review\", \"business_id\": \"RgDg-k9S5YD_BaxMckifkg\"},\n",
    "    {\"votes\": {\"funny\": 0, \"useful\": 0, \"cool\": 0}, \"user_id\": \"kj18hvJRPLepZPNL7ySKpg\", \"review_id\": \"uOLM0vvnFdp468ofLnszTA\", \"stars\": 3, \"date\": \"2011-06-02\", \"text\": \"Above average takeout with friendly staff. The sauce on the pan fried noodle is tasty. Dumplings are quite good.\", \"type\": \"review\", \"business_id\": \"RgDg-k9S5YD_BaxMckifkg\"},\n",
    "    {\"votes\": {\"funny\": 0, \"useful\": 0, \"cool\": 0}, \"user_id\": \"L5kqM35IZggaPTpQJqcgwg\", \"review_id\": \"b3u1RHmZTNRc0thlFmj2oQ\", \"stars\": 4, \"date\": \"2012-05-28\", \"text\": \"We order from Chang Jiang often and have never been disappointed.  The menu is huge, and can accomodate anyone's taste buds.  The service is quick, usually ready in 10 minutes.\", \"type\": \"review\", \"business_id\": \"RgDg-k9S5YD_BaxMckifkg\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bag_of_words_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReviewTransformer():\n",
    "    \"\"\"\n",
    "    Returns text reviews in lists\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        import nltk.tokenize\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        if type(x) == dict:\n",
    "            x = [x['text']]\n",
    "        else:\n",
    "            x = json.loads(x)['text']\n",
    "        ##X = [nltk.tokenize.word_tokenize(x) for x in X]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VectorizerTransformer():\n",
    "    \"\"\"\n",
    "    Returns count vectorizer\n",
    "    \"\"\"\n",
    "    def __init__(self, min_df, max_df):\n",
    "        import nltk.tokenize\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        self.trans = ReviewTransformer()\n",
    "        self.bag_of_words_vectorizer =CountVectorizer(min_df = min_df, max_df=max_df,\n",
    "                        stop_words=nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = [self.trans.transform(x) for x in X]\n",
    "        X = self.bag_of_words_vectorizer.fit_transform(X).toarray()\n",
    "        return X\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x = self.trans.transform(x)\n",
    "        x = self.bag_of_words_vectorizer.transform(x).toarray()\n",
    "        ##X = [nltk.tokenize.word_tokenize(x) for x in X]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoWEstimator():\n",
    "    def __init__(self, alpha, min_df, max_df):\n",
    "        self.trans = VectorizerTransformer(min_df,max_df)  \n",
    "        self.alpha = alpha\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):    \n",
    "        from sklearn import linear_model, utils, preprocessing\n",
    "        X = self.trans.fit(X)\n",
    "        self.model = linear_model.Ridge(alpha=self.alpha)\n",
    "        self.model.fit(X,y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.trans.transform(x)\n",
    "        model=self.model\n",
    "        self.y_pred = model.predict(x)\n",
    "        return self.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est = BoWEstimator(alpha=0.01, min_df=0.1, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = data[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"votes\": {\"funny\": 0, \"useful\": 2, \"cool\": 1}, \"user_id\": \"Xqd0DzHaiyRqVH3WRG7hzg\", \"review_id\": \"15SdjuK7DmYqUAj6rjGowg\", \"stars\": 5, \"date\": \"2007-05-17\", \"text\": \"dr. goldberg offers everything i look for in a general practitioner.  he\\'s nice and easy to talk to without being patronizing; he\\'s always on time in seeing his patients; he\\'s affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i\\'m sitting here trying to think of any complaints i have about him, but i\\'m really drawing a blank.\", \"type\": \"review\", \"business_id\": \"vcNAWiLM4dR7D2nwwJ7nCA\"}\\n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_stars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_stars = stars[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bow_model = est.fit(sample_data,sample_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_model = est.fit(data,stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "with open('bow_model.dill', 'w') as filename:\n",
    "    dill.dump(bow_model,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8659471568236796"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model.predict(records[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TfidfTransformer():\n",
    "    \"\"\"\n",
    "    Returns count vectorizer\n",
    "    \"\"\"\n",
    "    def __init__(self, min_df, max_df):\n",
    "        import nltk.tokenize\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        from sklearn.feature_extraction.text import TfidfTransformer\n",
    "        self.trans = VectorizerTransformer(min_df,max_df)\n",
    "        self.tfidf_vectorizer =TfidfTransformer()\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = self.trans.fit(X)\n",
    "        X = self.tfidf_vectorizer.fit_transform(X)\n",
    "        return X\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x = self.trans.transform(x)\n",
    "        x = self.tfidf_vectorizer.transform(x)\n",
    "        ##X = [nltk.tokenize.word_tokenize(x) for x in X]\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NormalizedEstimator():\n",
    "    def __init__(self, alpha, min_df, max_df):\n",
    "        self.trans = TfidfTransformer(min_df,max_df)  \n",
    "        self.alpha = alpha\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):    \n",
    "        from sklearn import linear_model, utils, preprocessing\n",
    "        X = self.trans.fit(X)\n",
    "        self.model = linear_model.Ridge(alpha=self.alpha)\n",
    "        self.model.fit(X,y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.trans.transform(x)\n",
    "        model=self.model\n",
    "        self.y_pred = model.predict(x)\n",
    "        return self.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est2 = NormalizedEstimator(alpha=0.001, min_df=0.1, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_model = est2.fit(sample_data,sample_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6801734117259688"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_model.predict(records[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_model = est2.fit(data,stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "with open('normalized_model.dill', 'w') as filename:\n",
    "    dill.dump(normalized_model,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BigramVectorizerTransformer():\n",
    "    \"\"\"\n",
    "    Returns count vectorizer\n",
    "    \"\"\"\n",
    "    def __init__(self, min_df, max_df):\n",
    "        import nltk.tokenize\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        self.trans = ReviewTransformer()\n",
    "        self.bag_of_words_vectorizer =CountVectorizer(min_df = min_df, max_df=max_df,ngram_range=(1,2),\n",
    "                        stop_words=nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = [self.trans.transform(x) for x in X]\n",
    "        X = self.bag_of_words_vectorizer.fit_transform(X).toarray()\n",
    "        return X\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x = self.trans.transform(x)\n",
    "        x = self.bag_of_words_vectorizer.transform(x).toarray()\n",
    "        ##X = [nltk.tokenize.word_tokenize(x) for x in X]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TruncateTransformer():\n",
    "    \"\"\"\n",
    "    Returns count vectorizer\n",
    "    \"\"\"\n",
    "    def __init__(self, min_df, max_df, n_components):\n",
    "        import nltk.tokenize\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        from sklearn.decomposition import TruncatedSVD\n",
    "        self.trans = BigramVectorizerTransformer(min_df,max_df)\n",
    "        self.svd =TruncatedSVD(n_components=n_components)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = self.trans.fit(X)\n",
    "        X = self.svd.fit_transform(X)\n",
    "        return X\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x = self.trans.transform(x)\n",
    "        x = self.svd.transform(x)\n",
    "        ##X = [nltk.tokenize.word_tokenize(x) for x in X]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BigramEstimator():\n",
    "    def __init__(self, alpha, min_df, max_df,n_components):\n",
    "        self.trans = TruncateTransformer(min_df,max_df,n_components)  \n",
    "        self.alpha = alpha\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):    \n",
    "        from sklearn import linear_model, utils, preprocessing\n",
    "        X = self.trans.fit(X)\n",
    "        self.model = linear_model.Ridge(alpha=self.alpha)\n",
    "        self.model.fit(X,y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.trans.transform(x)\n",
    "        model=self.model\n",
    "        self.y_pred = model.predict(x)\n",
    "        return self.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est3 = BigramEstimator(alpha=0.001, min_df=0.1, max_df=0.9, n_components = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_model = est3.fit(sample_data,sample_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "with open('bigram_model.dill', 'w') as filename:\n",
    "    dill.dump(bigram_model,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8789948774999603"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.predict(records[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# food_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_rest = df_rest[['categories', 'business_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_categories = df_rest['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_restaurants = []\n",
    "for items in list_categories:\n",
    "    if 'Restaurants'in items:\n",
    "        list_restaurants.append(True)\n",
    "    else:\n",
    "        list_restaurants.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rest['rest'] = list_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rest = df_rest.groupby('business_id').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_rest = df_rest[(df_rest['rest']==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_id_review = pd.concat([pd.Series(ids), pd.Series(reviews)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_id_review.columns = ['business_id', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_filtered =pd.merge(df_rest, df_id_review, on='business_id', how='outer').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>business_id</th>\n",
       "      <th>rest</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Good truck stop dining at the right price. We ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>If you like lot lizards, you'll love the Pine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Enjoyable experience for the whole family. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>One of my favorite truck stop diners with soli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Only went here once about a year and a half ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Great truck stop restaurant.  I've had breakfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Yeah, thats right a five freakin star rating. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Ate a Saturday morning breakfast at the Pine C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Attention fans of David Lynch.  Do stop by thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>With a recent addition of a truck driver for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>This is one of the best breakfasts I have had!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>hands down one of the best breakfasts my wife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>This is definitely not your usual truck stop. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>A delicious breakfast.  Amazing fresh bakery a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Don't be fooled because it's in a truck stop, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Continuing on my Saturday morning hangover the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Some times Jane and Michael Stern are on point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>I like this location better than the one near ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Restaurants]</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>True</td>\n",
       "      <td>OMG!  The bakery items at Pinecone are AMAZING...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>A really lovely surprise on a rather horrific ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>Very nice and clean place to have breakfast or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>I eat here regularily because it is consistent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>Unlimited hot coffee. I don't have any recolle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>Homestyle cooking at its best, dnt go to culve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>Nice simple homey diner. Very friendly staff, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>Love their breakfast menu &amp; they have friendly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>Went here for lunch with two co-workers, check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>Huge menu, fresh tasty food, reasonable prices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>Food was very good. I had the Reuben sandwich....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>True</td>\n",
       "      <td>My boyfriend and I came here to have breakfast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574297</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>While driving home yesterday, I spotted a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574298</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>All the food I tried was disappointing and fla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574299</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Unfortunately, I will not be able to rate the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574300</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>stopped in the minute I spotted the place. fak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574301</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Ordered all our food off GF menu.  Food was go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574302</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>My husband and I decided to give this place a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574303</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Cool ambience, inside is really open and clean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574304</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>We got here at 7:40pm, and ordered the Chicken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574305</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>The staff is friendly, definitely a positive! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574306</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Delicious healthy food.  I tried the baked chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574307</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Lots of variety; extensive gluten free menu. L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574308</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Being originally from California I'm always lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574309</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Located in the same shopping center as Whole F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574310</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>First off I am giving an extra star for clean,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574311</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Such a breath of fresh air! I love the food he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574312</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Love that there is a clean, fresh and actually...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574313</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>I had the art's unfried chicken, it was very d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574314</th>\n",
       "      <td>[American (New), Restaurants]</td>\n",
       "      <td>ZpB2O-WAbbRHdP0V8GrwXA</td>\n",
       "      <td>True</td>\n",
       "      <td>Let me start with my conclusion:  mediocre val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574315</th>\n",
       "      <td>[Food, Juice Bars &amp; Smoothies, American (New),...</td>\n",
       "      <td>OEUIE8VBa1BbBfr5EPcTOA</td>\n",
       "      <td>True</td>\n",
       "      <td>Hopefully this place gets better and better as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574316</th>\n",
       "      <td>[Food, Juice Bars &amp; Smoothies, American (New),...</td>\n",
       "      <td>OEUIE8VBa1BbBfr5EPcTOA</td>\n",
       "      <td>True</td>\n",
       "      <td>Barely open less than a week and I've been her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574317</th>\n",
       "      <td>[Food, Juice Bars &amp; Smoothies, American (New),...</td>\n",
       "      <td>OEUIE8VBa1BbBfr5EPcTOA</td>\n",
       "      <td>True</td>\n",
       "      <td>Healthy Food that Keeps this Realtor on the Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574318</th>\n",
       "      <td>[Food, Juice Bars &amp; Smoothies, American (New),...</td>\n",
       "      <td>OEUIE8VBa1BbBfr5EPcTOA</td>\n",
       "      <td>True</td>\n",
       "      <td>So happy to have this healthy eatery option ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574319</th>\n",
       "      <td>[Food, Juice Bars &amp; Smoothies, American (New),...</td>\n",
       "      <td>OEUIE8VBa1BbBfr5EPcTOA</td>\n",
       "      <td>True</td>\n",
       "      <td>Always been huge fan ever since the first Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574320</th>\n",
       "      <td>[Food, Juice Bars &amp; Smoothies, American (New),...</td>\n",
       "      <td>OEUIE8VBa1BbBfr5EPcTOA</td>\n",
       "      <td>True</td>\n",
       "      <td>New joint near my work and decided to give the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574321</th>\n",
       "      <td>[Bars, Turkish, Mediterranean, Nightlife, Loun...</td>\n",
       "      <td>yZXEELxi8KMwzXCHP345GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>Wonderful service very delicious and healthy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574322</th>\n",
       "      <td>[Bars, Turkish, Mediterranean, Nightlife, Loun...</td>\n",
       "      <td>yZXEELxi8KMwzXCHP345GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>These guys are really close to a 5 star.  Ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574323</th>\n",
       "      <td>[Bars, Turkish, Mediterranean, Nightlife, Loun...</td>\n",
       "      <td>yZXEELxi8KMwzXCHP345GQ</td>\n",
       "      <td>True</td>\n",
       "      <td>I had the seafood kabob. It was very tasty sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574324</th>\n",
       "      <td>[Kosher, Italian, Pizza, Restaurants]</td>\n",
       "      <td>BMjggIgOghBMEXPo8q7q3w</td>\n",
       "      <td>True</td>\n",
       "      <td>My new favorite restaurant.  They have 22 diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574325</th>\n",
       "      <td>[Kosher, Italian, Pizza, Restaurants]</td>\n",
       "      <td>BMjggIgOghBMEXPo8q7q3w</td>\n",
       "      <td>True</td>\n",
       "      <td>GreAt food awesome service . The best fish in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574326</th>\n",
       "      <td>[Kosher, Italian, Pizza, Restaurants]</td>\n",
       "      <td>BMjggIgOghBMEXPo8q7q3w</td>\n",
       "      <td>True</td>\n",
       "      <td>Walking into this place looks nice and well ke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574278 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               categories  \\\n",
       "0                                           [Restaurants]   \n",
       "1                                           [Restaurants]   \n",
       "2                                           [Restaurants]   \n",
       "3                                           [Restaurants]   \n",
       "4                                           [Restaurants]   \n",
       "5                                           [Restaurants]   \n",
       "6                                           [Restaurants]   \n",
       "7                                           [Restaurants]   \n",
       "8                                           [Restaurants]   \n",
       "9                                           [Restaurants]   \n",
       "10                                          [Restaurants]   \n",
       "11                                          [Restaurants]   \n",
       "12                                          [Restaurants]   \n",
       "13                                          [Restaurants]   \n",
       "14                                          [Restaurants]   \n",
       "15                                          [Restaurants]   \n",
       "16                                          [Restaurants]   \n",
       "17                                          [Restaurants]   \n",
       "18                                          [Restaurants]   \n",
       "19                  [American (Traditional), Restaurants]   \n",
       "20                  [American (Traditional), Restaurants]   \n",
       "21                  [American (Traditional), Restaurants]   \n",
       "22                  [American (Traditional), Restaurants]   \n",
       "23                  [American (Traditional), Restaurants]   \n",
       "24                  [American (Traditional), Restaurants]   \n",
       "25                  [American (Traditional), Restaurants]   \n",
       "26                  [American (Traditional), Restaurants]   \n",
       "27                  [American (Traditional), Restaurants]   \n",
       "28                  [American (Traditional), Restaurants]   \n",
       "29                  [American (Traditional), Restaurants]   \n",
       "...                                                   ...   \n",
       "574297                      [American (New), Restaurants]   \n",
       "574298                      [American (New), Restaurants]   \n",
       "574299                      [American (New), Restaurants]   \n",
       "574300                      [American (New), Restaurants]   \n",
       "574301                      [American (New), Restaurants]   \n",
       "574302                      [American (New), Restaurants]   \n",
       "574303                      [American (New), Restaurants]   \n",
       "574304                      [American (New), Restaurants]   \n",
       "574305                      [American (New), Restaurants]   \n",
       "574306                      [American (New), Restaurants]   \n",
       "574307                      [American (New), Restaurants]   \n",
       "574308                      [American (New), Restaurants]   \n",
       "574309                      [American (New), Restaurants]   \n",
       "574310                      [American (New), Restaurants]   \n",
       "574311                      [American (New), Restaurants]   \n",
       "574312                      [American (New), Restaurants]   \n",
       "574313                      [American (New), Restaurants]   \n",
       "574314                      [American (New), Restaurants]   \n",
       "574315  [Food, Juice Bars & Smoothies, American (New),...   \n",
       "574316  [Food, Juice Bars & Smoothies, American (New),...   \n",
       "574317  [Food, Juice Bars & Smoothies, American (New),...   \n",
       "574318  [Food, Juice Bars & Smoothies, American (New),...   \n",
       "574319  [Food, Juice Bars & Smoothies, American (New),...   \n",
       "574320  [Food, Juice Bars & Smoothies, American (New),...   \n",
       "574321  [Bars, Turkish, Mediterranean, Nightlife, Loun...   \n",
       "574322  [Bars, Turkish, Mediterranean, Nightlife, Loun...   \n",
       "574323  [Bars, Turkish, Mediterranean, Nightlife, Loun...   \n",
       "574324              [Kosher, Italian, Pizza, Restaurants]   \n",
       "574325              [Kosher, Italian, Pizza, Restaurants]   \n",
       "574326              [Kosher, Italian, Pizza, Restaurants]   \n",
       "\n",
       "                   business_id  rest  \\\n",
       "0       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "1       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "2       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "3       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "4       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "5       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "6       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "7       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "8       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "9       JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "10      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "11      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "12      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "13      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "14      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "15      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "16      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "17      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "18      JwUE5GmEO-sH1FuwJgKBlQ  True   \n",
       "19      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "20      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "21      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "22      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "23      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "24      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "25      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "26      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "27      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "28      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "29      uGykseHzyS5xAMWoN6YUqA  True   \n",
       "...                        ...   ...   \n",
       "574297  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574298  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574299  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574300  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574301  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574302  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574303  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574304  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574305  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574306  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574307  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574308  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574309  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574310  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574311  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574312  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574313  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574314  ZpB2O-WAbbRHdP0V8GrwXA  True   \n",
       "574315  OEUIE8VBa1BbBfr5EPcTOA  True   \n",
       "574316  OEUIE8VBa1BbBfr5EPcTOA  True   \n",
       "574317  OEUIE8VBa1BbBfr5EPcTOA  True   \n",
       "574318  OEUIE8VBa1BbBfr5EPcTOA  True   \n",
       "574319  OEUIE8VBa1BbBfr5EPcTOA  True   \n",
       "574320  OEUIE8VBa1BbBfr5EPcTOA  True   \n",
       "574321  yZXEELxi8KMwzXCHP345GQ  True   \n",
       "574322  yZXEELxi8KMwzXCHP345GQ  True   \n",
       "574323  yZXEELxi8KMwzXCHP345GQ  True   \n",
       "574324  BMjggIgOghBMEXPo8q7q3w  True   \n",
       "574325  BMjggIgOghBMEXPo8q7q3w  True   \n",
       "574326  BMjggIgOghBMEXPo8q7q3w  True   \n",
       "\n",
       "                                                     text  \n",
       "0       Good truck stop dining at the right price. We ...  \n",
       "1       If you like lot lizards, you'll love the Pine ...  \n",
       "2       Enjoyable experience for the whole family. The...  \n",
       "3       One of my favorite truck stop diners with soli...  \n",
       "4       Only went here once about a year and a half ag...  \n",
       "5       Great truck stop restaurant.  I've had breakfa...  \n",
       "6       Yeah, thats right a five freakin star rating. ...  \n",
       "7       Ate a Saturday morning breakfast at the Pine C...  \n",
       "8       Attention fans of David Lynch.  Do stop by thi...  \n",
       "9       With a recent addition of a truck driver for a...  \n",
       "10      This is one of the best breakfasts I have had!...  \n",
       "11      hands down one of the best breakfasts my wife ...  \n",
       "12      This is definitely not your usual truck stop. ...  \n",
       "13      A delicious breakfast.  Amazing fresh bakery a...  \n",
       "14      Don't be fooled because it's in a truck stop, ...  \n",
       "15      Continuing on my Saturday morning hangover the...  \n",
       "16      Some times Jane and Michael Stern are on point...  \n",
       "17      I like this location better than the one near ...  \n",
       "18      OMG!  The bakery items at Pinecone are AMAZING...  \n",
       "19      A really lovely surprise on a rather horrific ...  \n",
       "20      Very nice and clean place to have breakfast or...  \n",
       "21      I eat here regularily because it is consistent...  \n",
       "22      Unlimited hot coffee. I don't have any recolle...  \n",
       "23      Homestyle cooking at its best, dnt go to culve...  \n",
       "24      Nice simple homey diner. Very friendly staff, ...  \n",
       "25      Love their breakfast menu & they have friendly...  \n",
       "26      Went here for lunch with two co-workers, check...  \n",
       "27      Huge menu, fresh tasty food, reasonable prices...  \n",
       "28      Food was very good. I had the Reuben sandwich....  \n",
       "29      My boyfriend and I came here to have breakfast...  \n",
       "...                                                   ...  \n",
       "574297  While driving home yesterday, I spotted a new ...  \n",
       "574298  All the food I tried was disappointing and fla...  \n",
       "574299  Unfortunately, I will not be able to rate the ...  \n",
       "574300  stopped in the minute I spotted the place. fak...  \n",
       "574301  Ordered all our food off GF menu.  Food was go...  \n",
       "574302  My husband and I decided to give this place a ...  \n",
       "574303  Cool ambience, inside is really open and clean...  \n",
       "574304  We got here at 7:40pm, and ordered the Chicken...  \n",
       "574305  The staff is friendly, definitely a positive! ...  \n",
       "574306  Delicious healthy food.  I tried the baked chi...  \n",
       "574307  Lots of variety; extensive gluten free menu. L...  \n",
       "574308  Being originally from California I'm always lo...  \n",
       "574309  Located in the same shopping center as Whole F...  \n",
       "574310  First off I am giving an extra star for clean,...  \n",
       "574311  Such a breath of fresh air! I love the food he...  \n",
       "574312  Love that there is a clean, fresh and actually...  \n",
       "574313  I had the art's unfried chicken, it was very d...  \n",
       "574314  Let me start with my conclusion:  mediocre val...  \n",
       "574315  Hopefully this place gets better and better as...  \n",
       "574316  Barely open less than a week and I've been her...  \n",
       "574317  Healthy Food that Keeps this Realtor on the Go...  \n",
       "574318  So happy to have this healthy eatery option ri...  \n",
       "574319  Always been huge fan ever since the first Pres...  \n",
       "574320  New joint near my work and decided to give the...  \n",
       "574321  Wonderful service very delicious and healthy. ...  \n",
       "574322  These guys are really close to a 5 star.  Ther...  \n",
       "574323  I had the seafood kabob. It was very tasty sal...  \n",
       "574324  My new favorite restaurant.  They have 22 diff...  \n",
       "574325  GreAt food awesome service . The best fish in ...  \n",
       "574326  Walking into this place looks nice and well ke...  \n",
       "\n",
       "[574278 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rest_reviews = df_filtered['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_rest_reviews = rest_reviews[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Good truck stop dining at the right price. We love coming here on the weekends when we don't feel like cooking.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rest_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UniGramTransformer():\n",
    "    \"\"\"\n",
    "    Returns count vectorizer\n",
    "    \"\"\"\n",
    "    def __init__(self, min_df, max_df):\n",
    "        import nltk.tokenize\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        self.bag_of_words_vectorizer =CountVectorizer(min_df = min_df, max_df=max_df,\n",
    "                        stop_words='english')\n",
    "        self.unigram_dict = {}\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = self.bag_of_words_vectorizer.fit_transform(X)\n",
    "        features = self.bag_of_words_vectorizer.get_feature_names()\n",
    "        n = X.sum(axis=0)\n",
    "        count = n[0]\n",
    "        count = count.tolist()[0]\n",
    "        self.unigram_dict = dict(zip(features, count))\n",
    "        return self.unigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = UniGramTransformer(0.0001, 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_dict = trans.transform(rest_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15747"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiGramCountTransformer():\n",
    "    \"\"\"\n",
    "    Returns count vectorizer\n",
    "    \"\"\"\n",
    "    def __init__(self, min_df, max_df):\n",
    "        import nltk.tokenize\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        self.bag_of_words_vectorizer =CountVectorizer(min_df = min_df, max_df=max_df,ngram_range=(2,2),\n",
    "                        stop_words='english')\n",
    "        self.bigram_dict = {}\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = self.bag_of_words_vectorizer.fit_transform(X)\n",
    "        features = self.bag_of_words_vectorizer.get_feature_names()\n",
    "        n = X.sum(axis=0)\n",
    "        count = n[0]\n",
    "        count = count.tolist()[0]\n",
    "        self.bigram_dict = dict(zip(features, count))\n",
    "        return self.bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans = BiGramCountTransformer(0.0001, 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_dict = trans.transform(rest_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61677"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SpecialBigrams():\n",
    "    \"\"\"\n",
    "    Returns count vectorizer\n",
    "    \"\"\"\n",
    "    def __init__(self, min_uni, max_uni, min_bi, max_bi, smooth):\n",
    "        self.uni_trans = UniGramTransformer(min_uni, max_uni)\n",
    "        self.bi_trans = BiGramCountTransformer(min_bi, max_bi)\n",
    "        self.s = smooth\n",
    "        self.bigram_dict = {}\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        unigram_dict = self.uni_trans.transform(X)\n",
    "        bigram_dict = self.bi_trans.transform(X)\n",
    "        for bi in bigram_dict:\n",
    "            try:\n",
    "                bigram_dict[bi]=float(bigram_dict[bi])/((unigram_dict[bi.split()[0]]+self.s)*(unigram_dict[bi.split()[1]]+self.s))\n",
    "            except ValueError:\n",
    "                continue\n",
    "        sorted_bigrams = sorted(bigram_dict, key=bigram_dict.get ,reverse=True)\n",
    "        return str(sorted_bigrams[0:100])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans = SpecialBigrams(0.000001, 0.90, 0.00006, 0.90, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[u'hodge podge', u'himal chuli', u'hoity toity', u'roka akor', u'knick knacks', u'reina pepiada', u'cien agaves', u'baskin robbins', u'itty bitty', u'khai hoan', u'riff raff', u'grana padano', u'tutti santi', u'ropa vieja', u'gulab jamun', u'ore ida', u'dac biet', u'rula bula', u'hu tieu', u'innis gunn', u'tammie coe', u'alain ducasse', u'feng shui', u'leaps bounds', u'hors oeuvres', u'marche bacchus', u'uuu uuu', u'nooks crannies', u'celine dion', u'luc lac', u'krispy kreme', u'perrier jouet', u'deja vu', u'molecular gastronomy', u'puerto rican', u'vice versa', u'patatas bravas', u'lloyd wright', u'holyrood 9a', u'pura vida', u'lomo saltado', u'valle luna', u'nuoc mam', u'wal mart', u'bradley ogden', u'barnes noble', u'haricot vert', u'kao tod', u'ak yelpcdn', u'porta alba', u'khao soi', u'malai kofta', u'aguas frescas', u'loup mer', u'yadda yadda', u'mccormick schmick', u'yada yada', u'shiner bock', u'artery clogging', u'ritz carlton', u'womp womp', u'chino bandido', u'sous vide', u'homer simpson', u'harry potter', u'bells whistles', u'fra diavolo', u'highs lows', u'val vista', u'goi cuon', u'scantily clad', u'demi glace', u'pina colada', u'tsk tsk', u'turo turo', u'thit nuong', u'connective tissue', u'salo salo', u'betty boop', u'upward projects', u'cabo wabo', u'bim bap', u'fritto misto', u'ama ebi', u'haricot verts', u'ping pang', u'frou frou', u'lactose intolerant', u'har gow', u'toby keith', u'dom demarco', u'taj mahal', u'penn teller', u'kilt lifter', u'jw marriott', u'pin kaow', u'hob nobs', u'casey moore', u'pulp fiction', u'dulce leche']\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.transform(rest_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_rest_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihoods = []\n",
    "for bigram in bigrams:\n",
    "    w1 = bigram.split(' ')[0]\n",
    "    w2 = bigram.split(' ')[1]\n",
    "    ratio = bigrams[bigram]/ (unigrams[w1]*unigrams[w2])\n",
    "    likelihoods.append((bigram,ratio))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_likelihoods = sorted(likelihoods, key=lambda x: x[1], reverse= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'hong kong', 28739.609326123718),\n",
       " (u'valle luna', 26940.369175563868),\n",
       " (u'buon gusto', 25715.059344318746),\n",
       " (u'tutti santi', 25029.79422204203),\n",
       " (u'foie gras', 24773.733199746483),\n",
       " (u'kung pao', 24470.779846809499),\n",
       " (u'wi fi', 24068.538673996998),\n",
       " (u'osso bucco', 23781.48937519782),\n",
       " (u'pei wei', 23765.823335620542),\n",
       " (u'dac biet', 23107.021989056153),\n",
       " (u'kilt lifter', 22977.886928209355),\n",
       " (u'prix fixe', 22814.968951392992),\n",
       " (u'peter piper', 20957.452201273616),\n",
       " (u'bok choy', 20793.720575078652),\n",
       " (u'huevos rancheros', 20741.413214710603),\n",
       " (u'tammie coe', 20563.172015835389),\n",
       " (u'monte cristo', 20460.76327248184),\n",
       " (u'cracker barrel', 20159.972564544492),\n",
       " (u'surf turf', 20030.276395189474),\n",
       " (u'tex mex', 19994.694562156936),\n",
       " (u'si senor', 19929.384643054607),\n",
       " (u'coca cola', 19705.916620377844),\n",
       " (u'tikka masala', 19699.033446114936),\n",
       " (u'prickly pear', 19536.975309906906),\n",
       " (u'bloody mary', 19325.493074029786),\n",
       " (u'butternut squash', 19060.193841439439),\n",
       " (u'loco moco', 19013.169295858374),\n",
       " (u'saving grace', 18966.289978485944),\n",
       " (u'pf changs', 18655.10332537358),\n",
       " (u'santa fe', 18561.702106936555),\n",
       " (u'alice cooper', 18444.941723153152),\n",
       " (u'http www', 18177.683561975166),\n",
       " (u'rustler rooste', 18111.888977965911),\n",
       " (u'creme brulee', 18046.620909576846),\n",
       " (u'royal palms', 17805.400796582042),\n",
       " (u'royal taj', 17790.260149646172),\n",
       " (u'beaten path', 17714.678707747185),\n",
       " (u'thee pitts', 17453.309581341764),\n",
       " (u'pinot noir', 16916.32586316422),\n",
       " (u'capital grille', 16847.857179556806),\n",
       " (u'di beppo', 16574.977443319694),\n",
       " (u'bo hue', 16565.822526201042),\n",
       " (u'ho hum', 16537.477494352905),\n",
       " (u'nom nom', 16499.473898441727),\n",
       " (u'ruth chris', 16446.83476056462),\n",
       " (u'pet peeve', 16318.166472055827),\n",
       " (u'ins dives', 16161.995504055001),\n",
       " (u'mu shu', 15825.808000916213),\n",
       " (u'aunt chilada', 15408.896227677322),\n",
       " (u'clam chowder', 15278.442089854574),\n",
       " (u'insult injury', 15259.125575509523),\n",
       " (u'cave creek', 15246.669146468288),\n",
       " (u'neck woods', 15200.766715040758),\n",
       " (u'cotton candy', 15089.4148984152),\n",
       " (u'au jus', 15070.797334205836),\n",
       " (u'pane bianco', 14809.294914708198),\n",
       " (u'zen 32', 14798.606008749201),\n",
       " (u'hash browns', 14591.265913993182),\n",
       " (u'cole slaw', 14490.024958387989),\n",
       " (u'timely manner', 14298.827259293721),\n",
       " (u'panda express', 14123.317237110601),\n",
       " (u'moo shu', 13798.449590341328),\n",
       " (u'dimly lit', 13657.03567787618),\n",
       " (u'figs mascarpone', 13480.941406276772),\n",
       " (u'sea bass', 13393.323156667586),\n",
       " (u'bang buck', 13362.895945137956),\n",
       " (u'san diego', 13346.229601006082),\n",
       " (u'award winning', 13329.721872429878),\n",
       " (u'spam musubi', 13127.85098693016),\n",
       " (u'cherry blossom', 13085.807434406139),\n",
       " (u'lo mein', 12816.223160065329),\n",
       " (u'language barrier', 12724.115203526531),\n",
       " (u'casa grande', 12669.59601777313),\n",
       " (u'pf chang', 12519.003286129333),\n",
       " (u'com biz_photos', 12513.732815978437),\n",
       " (u'san francisco', 12409.731456121926),\n",
       " (u'tokyo lobby', 12224.091171078067),\n",
       " (u'screaming orgasm', 12120.702683168913),\n",
       " (u'track betting', 12092.600992994392),\n",
       " (u'pine nuts', 11947.995499366711),\n",
       " (u'wild thaiger', 11886.444620253711),\n",
       " (u'matzo ball', 11821.841033704946),\n",
       " (u'papa johns', 11723.950788002514),\n",
       " (u'los angeles', 11723.099362806932),\n",
       " (u'buca di', 11582.984236861055),\n",
       " (u'de gallo', 11509.568423570998),\n",
       " (u'ajo al', 11357.720161535188),\n",
       " (u'bowling alley', 11070.366290408636),\n",
       " (u'macadamia nut', 10941.204444718025),\n",
       " (u'ooey gooey', 10797.381641561255),\n",
       " (u'carne asada', 10757.506784105926),\n",
       " (u'miracle mile', 10122.458134585195),\n",
       " (u'chow mein', 10118.070915841048),\n",
       " (u'mahi mahi', 10085.521400682821),\n",
       " (u'co worker', 10084.558902140385),\n",
       " (u'au gratin', 10047.198222803891),\n",
       " (u'cheba hut', 9994.2546803522109),\n",
       " (u'corkage fee', 9972.7205896166979),\n",
       " (u'texas roadhouse', 9866.5831764843333),\n",
       " (u'peach cobbler', 9818.4909859640265)]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_likelihoods[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "food_bigrams = [[str(pair[0])] for pair in sorted_likelihoods[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "food_dic = dict(sorted_likelihoods[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'neck woods',\n",
       " u'au jus',\n",
       " u'pei wei',\n",
       " u'ooey gooey',\n",
       " u'wi fi',\n",
       " u'capital grille',\n",
       " u'miracle mile',\n",
       " u'beaten path',\n",
       " u'dac biet',\n",
       " u'tikka masala',\n",
       " u'texas roadhouse',\n",
       " u'aunt chilada',\n",
       " u'bang buck',\n",
       " u'royal palms',\n",
       " u'pet peeve',\n",
       " u'moo shu',\n",
       " u'buca di',\n",
       " u'royal taj',\n",
       " u'dimly lit',\n",
       " u'de gallo',\n",
       " u'cherry blossom',\n",
       " u'peter piper',\n",
       " u'mahi mahi',\n",
       " u'ho hum',\n",
       " u'si senor',\n",
       " u'casa grande',\n",
       " u'saving grace',\n",
       " u'creme brulee',\n",
       " u'papa johns',\n",
       " u'zen 32',\n",
       " u'au gratin',\n",
       " u'thee pitts',\n",
       " u'peach cobbler',\n",
       " u'bo hue',\n",
       " u'co worker',\n",
       " u'lo mein',\n",
       " u'valle luna',\n",
       " u'kilt lifter',\n",
       " u'pane bianco',\n",
       " u'cracker barrel',\n",
       " u'surf turf',\n",
       " u'pine nuts',\n",
       " u'cave creek',\n",
       " u'macadamia nut',\n",
       " u'tokyo lobby',\n",
       " u'buon gusto',\n",
       " u'cheba hut',\n",
       " u'track betting',\n",
       " u'chow mein',\n",
       " u'cotton candy',\n",
       " u'clam chowder',\n",
       " u'com biz_photos',\n",
       " u'foie gras',\n",
       " u'bowling alley',\n",
       " u'hash browns',\n",
       " u'alice cooper',\n",
       " u'san francisco',\n",
       " u'rustler rooste',\n",
       " u'prickly pear',\n",
       " u'award winning',\n",
       " u'language barrier',\n",
       " u'pf chang',\n",
       " u'butternut squash',\n",
       " u'ins dives',\n",
       " u'osso bucco',\n",
       " u'pinot noir',\n",
       " u'sea bass',\n",
       " u'spam musubi',\n",
       " u'corkage fee',\n",
       " u'matzo ball',\n",
       " u'di beppo',\n",
       " u'tammie coe',\n",
       " u'ruth chris',\n",
       " u'mu shu',\n",
       " u'screaming orgasm',\n",
       " u'kung pao',\n",
       " u'santa fe',\n",
       " u'bloody mary',\n",
       " u'http www',\n",
       " u'hong kong',\n",
       " u'wild thaiger',\n",
       " u'carne asada',\n",
       " u'loco moco',\n",
       " u'panda express',\n",
       " u'insult injury',\n",
       " u'tutti santi',\n",
       " u'pf changs',\n",
       " u'san diego',\n",
       " u'timely manner',\n",
       " u'prix fixe',\n",
       " u'huevos rancheros',\n",
       " u'bok choy',\n",
       " u'coca cola',\n",
       " u'ajo al',\n",
       " u'nom nom',\n",
       " u'figs mascarpone',\n",
       " u'monte cristo',\n",
       " u'los angeles',\n",
       " u'tex mex',\n",
       " u'cole slaw']"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['carne asada', 'strip mall', 'hole wall', 'ice cream',\n",
       "        'highly recommend', 'happy hour', 'dining room', 'years ago',\n",
       "        'chips salsa', 'parking lot', 'friday night', 'several times',\n",
       "        '10 minutes', 'last night', 'nothing special', 'fried rice',\n",
       "        'customer service', 'many times', 'even though', 'make sure',\n",
       "        'wait staff', 'next time', 'coming back', 'staff friendly',\n",
       "        'looks like', 'go wrong', 'every time', 'felt like', 'first time',\n",
       "        'come back', 'much better', 'feel like', 'tasted like',\n",
       "        'would recommend', 'long time', 'pretty much', 'mexican food',\n",
       "        'go back', 'last time', 'going back', 'looked like', 'best ever',\n",
       "        'fast food', 'one favorite', 'chinese food', 'pretty good',\n",
       "        'one thing', 'one best', 'back try', 'quality food', 'love place',\n",
       "        'really good', 'friendly service', 'service friendly',\n",
       "        'really nice', 'service always', 'great service', 'always get',\n",
       "        'would go', 'service great', 'great place', 'really like',\n",
       "        'always great', 'great food', 'always good', 'good service',\n",
       "        'food always', 'food great', 'food good', 'place go',\n",
       "        'service good', 'food service', 'good food', 'place great',\n",
       "        'like place', 'good place']], \n",
       "      dtype='|S16')"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(food_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
